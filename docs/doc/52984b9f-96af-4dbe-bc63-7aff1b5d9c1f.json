{
    "summary": "Both comments discuss code that handles user input and executes corresponding actions, with Comment A focusing on a Self-Operating Computer setup and error handling, while Comment B focuses on input parameter checks for dialog operations.",
    "details": [
        {
            "comment": "This code appears to be part of a Self-Operating Computer, which uses a model for generating responses. The main function takes in the model, terminal prompt, and voice mode as parameters. It initializes `WhisperMic` if voice mode is enabled.",
            "location": "\"/media/root/Toshiba XG3/works/self-operating-computer/docs/src/operate/dialog.py\":0-43",
            "content": "import sys\nimport os\nimport platform\nimport asyncio\nfrom prompt_toolkit.shortcuts import message_dialog\nfrom prompt_toolkit import prompt\nfrom operate.exceptions import ModelNotRecognizedException\nfrom operate.prompts import USER_QUESTION\nfrom operate.settings import Config\nfrom operate.utils.style import (\n    ANSI_GREEN,\n    ANSI_RESET,\n    ANSI_BLUE,\n    ANSI_YELLOW,\n    ANSI_RED,\n    ANSI_BRIGHT_MAGENTA,\n    style,\n)\nfrom operate.utils.os import (\n    keyboard_type,\n    search,\n    click,\n)\nfrom operate.actions import get_next_action, summarize\nfrom operate.utils.misc import parse_response\n# Load configuration\nconfig = Config()\ndef main(model, terminal_prompt, voice_mode=False):\n    \"\"\"\n    Main function for the Self-Operating Computer.\n    Parameters:\n    - model: The model used for generating responses.\n    - terminal_prompt: A string representing the prompt provided in the terminal.\n    - voice_mode: A boolean indicating whether to enable voice mode.\n    Returns:\n    None\n    \"\"\"\n    mic = None\n    # Initialize `WhisperMic`, if `voice_mode` is True"
        },
        {
            "comment": "Checks if voice mode is enabled, then tries to import and initialize the WhisperMic module. If the module is missing, it prints an error message and exits. Displays a message dialog unless the prompt was given directly via terminal. Skips objective prompt if provided as an argument or prompts for input through the WhisperMic in voice mode. Clears the console on all operating systems except Windows where it uses \"cls\" command.",
            "location": "\"/media/root/Toshiba XG3/works/self-operating-computer/docs/src/operate/dialog.py\":45-79",
            "content": "    validation(model, voice_mode)\n    if voice_mode:\n        try:\n            from whisper_mic import WhisperMic\n            # Initialize WhisperMic if import is successful\n            mic = WhisperMic()\n        except ImportError:\n            print(\n                \"Voice mode requires the 'whisper_mic' module. Please install it using 'pip install -r requirements-audio.txt'\"\n            )\n            sys.exit(1)\n    # Skip message dialog if prompt was given directly\n    if not terminal_prompt:\n        message_dialog(\n            title=\"Self-Operating Computer\",\n            text=\"Ask a computer to do anything.\",\n            style=style,\n        ).run()\n    else:\n        print(\"Running direct prompt...\")\n    print(\"SYSTEM\", platform.system())\n    # Clear the console\n    if platform.system() == \"Windows\":\n        os.system(\"cls\")\n    else:\n        print(\"\\033c\", end=\"\")\n    if terminal_prompt:  # Skip objective prompt if it was given as an argument\n        objective = terminal_prompt\n    elif voice_mode:\n        print("
        },
        {
            "comment": "The code is capturing voice input from the microphone and storing it in the \"objective\" variable. If an error occurs while capturing voice input, it will print an error message and exit. Otherwise, it prints a message from the self-operating computer and the user's question, then stores the objective as the user's message content. It then enters a loop where it waits for the next action by calling a function \"get_next_action\" with the current messages and objective. If an error occurs while waiting for the next action, it will print an error message.",
            "location": "\"/media/root/Toshiba XG3/works/self-operating-computer/docs/src/operate/dialog.py\":80-108",
            "content": "            f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_RESET} Listening for your command... (speak now)\"\n        )\n        try:\n            objective = mic.listen()\n        except Exception as e:\n            print(f\"{ANSI_RED}Error in capturing voice input: {e}{ANSI_RESET}\")\n            return  # Exit if voice input fails\n    else:\n        print(f\"{ANSI_GREEN}[Self-Operating Computer]\\n{ANSI_RESET}{USER_QUESTION}\")\n        print(f\"{ANSI_YELLOW}[User]{ANSI_RESET}\")\n        objective = prompt(style=style)\n    assistant_message = {\"role\": \"assistant\", \"content\": USER_QUESTION}\n    user_message = {\n        \"role\": \"user\",\n        \"content\": f\"Objective: {objective}\",\n    }\n    messages = [assistant_message, user_message]\n    loop_count = 0\n    while True:\n        if config.debug:\n            print(\"[loop] messages before next action:\\n\\n\\n\", messages[1:])\n        try:\n            response = asyncio.run(get_next_action(model, messages, objective))\n            action = parse_response(response)\n            action_type = action.get(\"type\")"
        },
        {
            "comment": "The code is handling exceptions for a ModelNotRecognizedException and any other exception that occurs during the execution. It then checks if the action_type is \"DONE\", if so, it prints a completion message, summarizes the model, and exits. If the action_type is not unknown, it prints an act message along with the action type and detail, and initializes an empty function_response variable if the action type is \"SEARCH\".",
            "location": "\"/media/root/Toshiba XG3/works/self-operating-computer/docs/src/operate/dialog.py\":109-138",
            "content": "            action_detail = action.get(\"data\")\n        except ModelNotRecognizedException as e:\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_RED}[Error] -> {e} {ANSI_RESET}\"\n            )\n            break\n        except Exception as e:\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_RED}[Error] -> {e} {ANSI_RESET}\"\n            )\n            break\n        if action_type == \"DONE\":\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_BLUE} Objective complete {ANSI_RESET}\"\n            )\n            summary = summarize(model, messages, objective)\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_BLUE} Summary\\n{ANSI_RESET}{summary}\"\n            )\n            break\n        if action_type != \"UNKNOWN\":\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_BRIGHT_MAGENTA} [Act] {action_type} {ANSI_RESET}{action_detail}\"\n            )\n        function_response = \"\"\n        if action_type == \"SEARCH\":"
        },
        {
            "comment": "This code block checks the action type and performs the corresponding action. If the action type is not recognized, it prints an error message and breaks the loop. It also logs the act completion and updates the messages list for further processing.",
            "location": "\"/media/root/Toshiba XG3/works/self-operating-computer/docs/src/operate/dialog.py\":139-170",
            "content": "            function_response = search(action_detail)\n        elif action_type == \"TYPE\":\n            function_response = keyboard_type(action_detail)\n        elif action_type == \"CLICK\":\n            function_response = click(action_detail)\n        else:\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_RED}[Error] something went wrong :({ANSI_RESET}\"\n            )\n            print(\n                f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_RED}[Error] AI response\\n{ANSI_RESET}{response}\"\n            )\n            break\n        print(\n            f\"{ANSI_GREEN}[Self-Operating Computer]{ANSI_BRIGHT_MAGENTA} [Act] {action_type} COMPLETE {ANSI_RESET}{function_response}\"\n        )\n        message = {\n            \"role\": \"assistant\",\n            \"content\": function_response,\n        }\n        messages.append(message)\n        loop_count += 1\n        if loop_count > 15:\n            break\ndef validation(model, voice_mode):\n    \"\"\"\n    Validate the input parameters for the dialog operation."
        },
        {
            "comment": "This code checks the input parameters for dialog operation and raises SystemExit if the input parameters are invalid. It also prints a message indicating which API key is missing based on the chosen model.",
            "location": "\"/media/root/Toshiba XG3/works/self-operating-computer/docs/src/operate/dialog.py\":172-191",
            "content": "    Args:\n        model (str): The model to be used for the dialog operation.\n        voice_mode (bool): Flag indicating whether to use voice mode.\n    Raises:\n        SystemExit: If the input parameters are invalid.\n    \"\"\"\n    if voice_mode and not config.openai_api_key:\n        print(\"To use voice mode, please add an OpenAI API key\")\n        sys.exit(1)\n    if model == \"gpt-4-vision-preview\" and not config.openai_api_key:\n        print(\"To use `gpt-4-vision-preview` add an OpenAI API key\")\n        sys.exit(1)\n    if model == \"gemini-pro-vision\" and not config.google_api_key:\n        print(\"To use `gemini-pro-vision` add a Google API key\")\n        sys.exit(1)"
        }
    ]
}